---
title: SE_based_on_unlabled_data
mathjax: true
date: 2024-10-23 23:58:12
categories: 学术
tags:
- ICASSP 
- 音频处理
---

# 无监督音频增强相关技术学习

## pre数学知识

### （1）基础线性代数和高数内容

### （2）广义逆矩阵

> 定义：如果对于一个线性方程组$Ax=b$，如果存在一个矩阵$A^{-}$满足：$\forall b$，$x=A^{-}b$都是原方程的解，那么我们称$A^{-}$为$A$的广义逆矩阵，又叫伪逆矩阵。（伪逆矩阵一般不止一个。

广义逆矩阵意味着什么？如果$A^-$是$A$的广义逆，一条充要条件：    

- 必要性，显然有$AA^-A=A$成立；充分性上，$\forall b$，取$Ay=b$，那么显然有$AA^-Ay=Ay$成立，也就意味着$\forall b$，有$AA^-b=b$成立.


求解广义逆矩阵的通法：

根据非满秩矩阵$A$ 的相抵标准型：$\exist$ 可逆方阵$P、Q$使得

$$
PAQ=\begin{pmatrix} E_r & 0 \\ 0 & 0 \end{pmatrix}
$$

于是：

$$
A=P^{-1}\begin{pmatrix} E_r & 0 \\ 0 & 0 \end{pmatrix} Q^{-1}，
注意M会是A的反形矩阵.
$$

直觉上显然有：

$$
M=Q\begin{pmatrix} E_r & X \\ Y & Z \end{pmatrix}P
$$

会是$A$的广义逆的通解形式！

### （3）一些信号处理的知识

一、形象地，我们可以用波形图来描述一段音频，横轴代表时间、纵轴代表振幅：

![](https://static.emastered.com/images/blog-assets/7093.webp)

但是波形图在频率信息的表征上仍然不够直观，为了弥补这一点引入了频谱图的工作：与波形图一样，频谱图上的时间也沿着 x 轴前进。不同的是，另一个轴代表频谱，低频在底部，一直延伸到人类听觉的最高处。

沿着 y 轴，您将看到构成声音的所有单个频率；基频或根频，使声音具有感知音高，谐波则构成声音的独特色彩和音调。

特定声音的响度由信号的 "热图 "来定义。热图可以用颜色或强度表示但从本质上讲，声音越大，它的亮度就越高。吉他手都喜欢这样/doge

![](https://static.emastered.com/images/blog-assets/7084.webp)

傅里叶变换（Fourier Transform）是一种数学工具，用于将信号从时域转换到频域。它通过将一个函数表示为一系列正弦和余弦函数的叠加，帮助我们分析信号的频率成分。

傅里叶变换的定义:

对于一个可积的函数 $ f(t) $，其傅里叶变换定义为：

$$
F(\omega) = \int_{-\infty}^{+\infty} f(t) e^{-i \omega t} \, dt
$$

$其中，( F(\omega) \) 是频域表示，\( \omega \) 是角频率，\( i ) 是虚数单位。$

傅里叶逆变换:

傅里叶逆变换则将频域信号转换回时域，定义为：

$$
f(t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} F(\omega) e^{i \omega t} \, d\omega
$$


二、 $SNR\_loss$ 衡量信号相似度的函数定义：

$$
\begin{equation}
    \begin{cases}
        s_{target}=\frac{<\hat{s},s>s}{ {\mid s\mid }^2 } \\
        e_{noise}=\hat{s}-s_{target}\\
        SNR(s,\hat{s}) =10log \frac{\mid s_{target}\mid ^2}{\mid e_{noise}\mid ^2} 
    \end{cases}
\end{equation}
$$


## 开始介绍一些SE的工作基础（Signal Enhance）

### 无监督音频信号分离技术（Unsupervised Sound Separation）

参考文献：[Unsupervised Sound Separation Using Mixture Invariant Training](https://arxiv.org/pdf/2006.12701)



我们传统的有监督音频分离技术任务，需要训练数据同时包含混合音频和每个音轨单独的音频；这对训练数据的要求很高、导致收集数据集难度很高。基于此提出来一种无监督的训练方法，这种方法只需要混杂の的原始音频即可。训练算法如下：

<center>
    <img src="/pics/mixit.png">
</center>


算法的基本思想是：既然没有原始的音频，那我们不如直接拿来原始混杂的音频，经过一个`DNN`之后，得到期待的分离开的每个音轨的纯净音频，再将这些音频重新组合得到一系列混合音频，从这些混合音频中挑选和原始输入混杂音频相似度最好的几段计算损失函数来反向传播更新参数。

像上图里面的例子：我们考虑每次抽取两段音频$x_1$、$x_2$(都是混杂的有很多道音轨的输入，比如同时有人说话的声音、鸟儿鸣叫的声音、车子按喇叭的声音...)作为输入，设$\hat{x}=(x_1+x_2)$，我们的模型描述为一个参数集合为$\theta$的函数$f_{\theta}$，我们将输入传入这个模型得到$\hat{s}=f_{\theta}(\hat{x})$ ，为了方便处理输出的$\hat{s}$最多有$M$个元素，每个元素期望得到的每一条音轨的音频，比如只有人说话的声音。然后我们通过一个矩阵$A \in matrix(2,M)$，来再度合成混杂信号$ x_1^{\*} , x_2^{\*}=A\hat{s} $ 。这里的$A$是一个元素非0即1的矩阵，每一个位置表示混杂信号包不包含$s$中的某一种元素。最后在通过

<center>
$Loss=SNR({（x_1,x_2）},A(f_{\theta}(\hat{x})))$
</center>

来衡量对原始音频的分离效果。

notice： 为什么要采用这种先分离在合成的方法来达到分离的训练？

> 第一点（必要性）：我们只有混杂的信号、并没有原始的每一条音轨的信号，所以我们无法根据原始音轨和模型分离出的音轨来计算$Loss$函数来进行梯度反向更新参数。

> 第二点（充分性）：直观上来说假设我们模型不能很好的分离各个音轨的音频，那么最后面的$A$无论怎么选$Loss$肯定都是很高的。